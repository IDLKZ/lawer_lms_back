DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@db.YOUR_PROJECT.supabase.co:5432/postgres
OPENAI_API_KEY=your_openai_api_key_here
SECRET_KEY=your_secret_key_here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
OPENROUTER_API_KEY=your_openrouter_api_key_here

# LLM Settings
# Provider: 'ollama' for local Ollama, 'openrouter' or 'openai' for cloud services
LLM_PROVIDER=ollama
LLM_MODEL=llama3
LLM_TEMPERATURE=0.1

# Ollama Settings (when LLM_PROVIDER=ollama)
OLLAMA_URL=http://localhost:11434

# Cloud LLM Settings (when LLM_PROVIDER=openrouter or openai)
# For OpenRouter: https://openrouter.ai/api/v1
# For OpenAI: https://api.openai.com/v1
# For Groq: https://api.groq.com/openai/v1
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=your_api_key_here
LLM_USE_NER=bool

# Example cloud models:
# OpenRouter: meta-llama/llama-3.1-70b-instruct, anthropic/claude-3.5-sonnet
# OpenAI: gpt-4-turbo, gpt-4, gpt-3.5-turbo
# Groq: llama-3.1-70b-versatile, mixtral-8x7b-32768
# CORS Settings
# For development, use "*" to allow all origins
# For production, specify exact origins separated by commas
CORS_ORIGINS=*
# Alternative for production:
# CORS_ORIGINS=http://localhost:3000,https://yourdomain.com

CORS_ALLOW_CREDENTIALS=True
CORS_ALLOW_METHODS=*
CORS_ALLOW_HEADERS=*
